# Create pretraining_template column in ds
def apply_prompt_template(row, tokenizer, max_length=250):
    """
    Apply a prompt template to a row of the dataset.

    Args:
        row: Row of dataset
        tokenizer: Huggingface tokenizer
        max_length: Maximum length of source text in words.
    Returns:
        row: Row with prompt template applied in "text_prompt" column.
    """

    # Keep only first max_length words of text
    text_preview = " ".join(row["text"].split()[:max_length])
    document_context = "###\n" + text_preview + "\n###\n"
    prompt = """Does the previous paragraph demarcated within ### and ###
    contain informative signal for pre-training a large-language model in Swedish?
    An informative datapoint should be well-formatted, contain some
    usable knowledge of the world, and strictly NOT have any harmful,
    racist, sexist, autogenerated or autotranslated marketing, etc. content.

    OPTIONS:

    - yes
    - no
    """

    text = document_context + prompt

    messages = [
        {
            "role": "user",
            "content": text,
        }
    ]

    text_prompt = tokenizer.apply_chat_template(messages, tokenize=False)
    row["text_prompt"] = text_prompt
    return row
